# Ansible

Configuration management and deployment automation for blockchain nodes.

## Directory Structure

```
ansible/
├── ansible.cfg              # Ansible configuration
├── requirements.yml         # Galaxy collections
├── playbooks/
│   ├── ethereum.yml         # Docker deployment (Reth+LH, Geth+Prysm)
│   ├── erigon.yml           # Binary deployment (Erigon+Caplin)
│   ├── raid.yml             # RAID-0 setup (bare metal)
│   └── site.yml             # Entry point (imports ethereum + erigon)
├── inventory/
│   ├── ethereum_mainnet_aws_terraform_state.yml       # Auto-generated (Mainnet AWS)
│   ├── ethereum_mainnet_latitude_terraform_state.yml   # Auto-generated (Mainnet Latitude)
│   ├── ethereum_sepolia_aws_terraform_state.yml        # Auto-generated (Sepolia AWS)
│   ├── ethereum_sepolia_latitude_terraform_state.yml   # Auto-generated (Sepolia Latitude)
│   ├── ethereum_sepolia_hosts.yml                      # Static inventory (optional)
│   └── group_vars/
│       ├── all/                  # Global defaults (certbot email, data mount)
│       │   └── main.yml
│       ├── ethereum/             # Docker chain config + vault secrets
│       │   ├── main.yml          # Versions, images, ports, vault refs
│       │   └── vault.yml         # Encrypted secrets (ansible-vault create)
│       ├── erigon/               # Erigon binary config + vault secrets
│       │   ├── main.yml          # Version, RPC, Caplin, vault refs
│       │   └── vault.yml         # Encrypted secrets (ansible-vault create)
│       ├── node_archive/         # Archive node overrides (prune.mode, commitment-history)
│       │   └── main.yml
│       ├── network_mainnet/      # Mainnet network overrides
│       │   └── main.yml
│       ├── network_sepolia/      # Sepolia network overrides (chain, RPC tuning)
│       │   └── main.yml
│       └── platform_latitude/    # Latitude BM platform overrides
│           ├── main.yml          # SSH user, firewall, vault refs for AWS creds
│           └── vault.yml         # Encrypted AWS creds (ansible-vault create)
└── roles/
    ├── common/              # System setup, disk, tuning, optional Docker
    ├── raid/                # RAID-0 auto-discovery (bare metal)
    ├── ethereum/            # Docker client deployment (Reth+LH, Geth+Prysm)
    ├── erigon/              # Erigon binary build (built-in Caplin CL)
    └── haproxy/             # Reverse proxy (TLS, API key auth, WebSocket)
```

## Inventory (Auto-Generated from Terraform State)

Ansible reads hosts and host variables directly from Terraform state using the `cloud.terraform.terraform_provider` inventory plugin. This plugin reads `ansible_host` resources via `terraform show`. The inventory config file is **auto-generated by Terraform** at `ansible/inventory/` when you run `terraform apply`.

```bash
# Requires: terraform login (or TF_TOKEN_app_terraform_io)
cd ansible
ansible-inventory -i inventory/ethereum_mainnet_aws_terraform_state.yml --list
```

Inventory groups include:
- `ethereum`, `erigon` (role-based, determines which playbook to use)
- `chain_ethereum` (chain-level grouping for all Ethereum nodes regardless of role)
- `network_mainnet`, `network_sepolia`
- `platform_latitude`, `platform_aws`
- `node_full`, `node_archive`
- `execution_geth`, `execution_reth`, `execution_erigon`
- `consensus_prysm`, `consensus_lighthouse`, `consensus_caplin`

> **Note:** The bare chain name (`ethereum`) is NOT used as a group. The `ethereum` group comes only from the role field (`role = "ethereum"` in `nodes.tfvars`). This prevents `group_vars/ethereum/` from overriding `group_vars/erigon/` on Erigon nodes due to Ansible's alphabetical group precedence.

## Roles

### RAID Role
Sets up RAID-0 on bare metal servers with multiple data disks:
- Auto-discovers OS disk and excludes it (handles RAID-1 root via `/sys/block/mdX/slaves/`)
- Finds all available unmounted data disks
- Single disk: uses directly (no RAID)
- Multiple disks: creates RAID-0 array (`/dev/md127`)
- Formats with ext4, mounts to `/data`
- Saves mdadm config + updates initramfs for persistence
- Idempotent: skips if RAID already exists and is mounted

### Common Role
Prepares the system for running blockchain nodes:
- OS packages and tuning
- Service user creation (`ethereum`, UID 2000)
- Data volume mount (skipped if `/data` already mounted by RAID role)
- Docker installation (skipped when `install_docker: false` for Erigon nodes)

### Ethereum Role
Deploys execution + consensus clients via Docker Compose:
- Reth + Lighthouse (archive nodes)
- Geth + Prysm (full nodes)

### Erigon Role
Deploys Erigon v3 as a native binary (no Docker):
- Builds Erigon from source as service user (Go toolchain + `make erigon`)
- Built-in Caplin consensus client (single binary, no separate beacon node)
- Systemd `erigon` service with `LD_LIBRARY_PATH` for `libsilkworm_capi.so`
- Version marker (`/opt/erigon/.erigon_version`) for upgrade detection
- UFW firewall configuration (Latitude BM only)
- Supports both Mainnet and Sepolia via group variable precedence

### HAProxy Role
Deploys HAProxy as a reverse proxy for RPC endpoints on the same node:
- Let's Encrypt TLS via Certbot + AWS Route 53 DNS-01 challenge
- UUID4 API key authentication (`X-API-Key` header or `?apikey=` URL parameter)
- File-based key lookup (keys stored in `/etc/haproxy/api-keys/`, never inline)
- WebSocket upgrade detection with extended timeouts (3600s server/client, 1h tunnel)
- HTTP to HTTPS redirect (port 80 -> 443)
- Auto-renewal via certbot systemd timer + deploy hook (rebuilds PEM bundle, reloads HAProxy)
- Optional HAProxy stats page (localhost:8404) and Prometheus metrics exporter (port 8405)
- UFW firewall rules for ports 80/443 (Latitude BM only)

**TLS certificate flow:**
- **AWS EC2:** Certbot uses IAM instance profile for Route 53 DNS validation (no credentials to manage)
- **Latitude BM:** AWS credentials deployed from Ansible vault to `/root/.aws/credentials` for Route 53 access

## Configuration

**Docker nodes (Reth+Lighthouse, Geth+Prysm):** Client versions and defaults live in `ansible/inventory/group_vars/ethereum/main.yml`.

**Erigon nodes:** Version and config live in `ansible/inventory/group_vars/erigon/main.yml`. Erigon defaults to **full** mode (no `--prune.mode` flag).

**Archive overrides:** Archive-specific settings (`erigon_prune_mode: archive`, `erigon_commitment_history: true`) live in `group_vars/node_archive/main.yml`. Applied automatically when `node_type = "archive"` in Terraform or `node_archive` group in static inventory.

**Network overrides:** Network-specific settings in `group_vars/network_mainnet/` and `group_vars/network_sepolia/`. Sepolia overrides apply to both Docker and Erigon nodes (checkpoint sync URL, `ethereum_network: sepolia`, Erigon RPC tuning). Ansible merges group_vars alphabetically - `node_archive` > `network_sepolia` > `ethereum`/`erigon`, so archive and Sepolia values override the base config automatically.

**Checkpoint sync URLs (per network):**

| Network | URL | Provider | Status |
|---------|-----|----------|--------|
| Mainnet | `https://mainnet.checkpoint.sigp.io` | Sigma Prime | Stable |
| Sepolia | `http://unstable.sepolia.beacon-api.nimbus.team` | Nimbus team | Unstable |

Checkpoint sync is optional but recommended - substantially faster than syncing from genesis. Configured in `group_vars/ethereum/main.yml` (mainnet default) and overridden in `group_vars/network_sepolia/main.yml` for Sepolia. Standard Sepolia endpoints (`beaconstate.info`, `ethpandaops.io`, `chainsafe.io`) do not serve blobs, which Lighthouse v8.0.0+ requires for post-Deneb checkpoint sync. If the Nimbus endpoint becomes unavailable, remove the `checkpoint_sync_url` for Sepolia to sync from genesis.

**L2 beacon endpoint:** Lighthouse archive nodes (mainnet and Sepolia) expose the Beacon API on port 5052. This provides an L1 beacon endpoint for L2 chains (Arbitrum, Optimism, Base, etc.) that need historical blob data via the `/eth/v1/beacon/blob_sidecars/{block_id}` API. The `--supernode` and `--prune-blobs=false` flags ensure full blob retention.

**HAProxy configuration:** The HAProxy role is included in both `ethereum.yml` and `erigon.yml` playbooks with tag `haproxy`. Enabled when `haproxy_enabled: true` (set in `group_vars/erigon/main.yml` and `group_vars/ethereum/main.yml`). Backend ports auto-map from execution client ports.

**HAProxy required variables:**

| Variable | Where to set | Purpose |
|----------|-------------|---------|
| `haproxy_domain` | Per-node via Terraform (`domain` in `nodes.tfvars`) | Domain for TLS cert (Route 53 A record auto-created) |
| `haproxy_certbot_email` | `group_vars/all/main.yml` (plaintext) | Let's Encrypt registration email |
| `vault_haproxy_api_key` | `group_vars/<role>/vault.yml` (encrypted) | UUID4 API key for RPC authentication |

**HAProxy secrets (Ansible vault):**

Secrets are stored in per-role encrypted vault files so each node group has its own API key:

| Secret | Vault file | Referenced by |
|--------|-----------|--------------|
| `vault_haproxy_api_key` | `group_vars/erigon/vault.yml` | `haproxy_api_key` in `erigon/main.yml` |
| `vault_haproxy_api_key` | `group_vars/ethereum/vault.yml` | `haproxy_api_key` in `ethereum/main.yml` |
| `vault_haproxy_stats_password` | `group_vars/erigon/vault.yml` | `haproxy_stats_password` in `erigon/main.yml` |
| `vault_haproxy_stats_password` | `group_vars/ethereum/vault.yml` | `haproxy_stats_password` in `ethereum/main.yml` |
| `vault_haproxy_certbot_aws_access_key` | `group_vars/platform_latitude/vault.yml` | `haproxy_certbot_aws_access_key` in `platform_latitude/main.yml` |
| `vault_haproxy_certbot_aws_secret_key` | `group_vars/platform_latitude/vault.yml` | `haproxy_certbot_aws_secret_key` in `platform_latitude/main.yml` |

> AWS EC2 nodes use IAM instance profiles for Certbot Route 53 - no AWS credentials needed. Only Latitude BM nodes need the `platform_latitude/vault.yml` file.

See the [Ansible Vault Setup](#ansible-vault-setup) section below for step-by-step instructions.

**HAProxy optional variables** (all have defaults in `roles/haproxy/defaults/main.yml`):

| Variable | Default | Purpose |
|----------|---------|---------|
| `haproxy_stats_enabled` | `true` | Stats page on localhost:8404 |
| `haproxy_stats_password` | `""` | Stats page auth password (set via per-role vault) |
| `haproxy_metrics_enabled` | `false` | Prometheus metrics exporter |
| `haproxy_maxconn` | `500000` | Max connections |
| `haproxy_backend_ws_enabled` | `true` | WebSocket backend |
| `haproxy_firewall_enabled` | `false` | UFW rules for 80/443 (enable on BM) |

See [Static Inventory Guide](static-inventory.md) for deploying without Terraform.

## Ansible Vault Setup

All secrets (API keys, passwords, AWS credentials) are stored in encrypted Ansible vault files. Secrets never exist in plaintext on disk - `ansible-vault create` opens an editor and saves the file encrypted directly.

### How it works

Unencrypted `main.yml` files reference vault variables using `{{ vault_* }}` lookups. The actual secret values live only in encrypted `vault.yml` files. Secrets are scoped per role group so each node type has its own API key:

```
inventory/group_vars/
├── ethereum/
│   ├── main.yml      # haproxy_api_key: "{{ vault_haproxy_api_key | default('') }}"
│   └── vault.yml     # vault_haproxy_api_key: (encrypted, Docker nodes)
├── erigon/
│   ├── main.yml      # haproxy_api_key: "{{ vault_haproxy_api_key | default('') }}"
│   └── vault.yml     # vault_haproxy_api_key: (encrypted, Erigon nodes)
└── platform_latitude/
    ├── main.yml      # haproxy_certbot_aws_access_key: "{{ vault_haproxy_certbot_aws_* | default('') }}"
    └── vault.yml     # vault_haproxy_certbot_aws_*: (encrypted, Latitude BM only)
```

### Required vault variables

**Per-role** (`group_vars/erigon/vault.yml`, `group_vars/ethereum/vault.yml`) - all deployments:

| Variable | Purpose |
|----------|---------|
| `vault_haproxy_api_key` | UUID4 API key for RPC authentication |
| `vault_haproxy_stats_password` | HAProxy stats page password |

> Create a separate vault for each role you deploy. Use different API keys per role group.

**Latitude BM** (`group_vars/platform_latitude/vault.yml`) - bare metal only:

| Variable | Purpose |
|----------|---------|
| `vault_haproxy_certbot_aws_access_key` | IAM access key (Route 53 permissions for Certbot) |
| `vault_haproxy_certbot_aws_secret_key` | IAM secret key |

> AWS EC2 nodes use IAM instance profiles - no AWS credentials needed in vault.

### Step 1: Create vault password file

Create the vault password file referenced by `ansible.cfg` (`vault_password_file = .vault_password`):

```bash
cd ansible
echo "your-vault-password" > .vault_password
chmod 600 .vault_password
```

> `.vault_password` is in `.gitignore` - never commit this file. Store the password securely and share it with team members out-of-band.

### Step 2: Create per-role vaults (API key + stats password)

Each role group gets its own vault so different node types use different API keys. `ansible-vault create` opens your `$EDITOR` and saves encrypted on disk - secrets never touch disk in plaintext.

Create one vault per role you deploy:

```bash
cd ansible

# --- Docker nodes (Reth+Lighthouse, Geth+Prysm) ---
uuidgen  # Generate a UUID4 API key, copy the output
ansible-vault create inventory/group_vars/ethereum/vault.yml

# --- Erigon nodes (Erigon+Caplin) ---
uuidgen  # Generate a DIFFERENT UUID4 for Erigon nodes
ansible-vault create inventory/group_vars/erigon/vault.yml
```

Your editor opens for each file. Add the required variables, save, and close:

```yaml
---
vault_haproxy_api_key: "<paste-your-generated-uuid4>"
vault_haproxy_stats_password: "<your-stats-password>"
```

> Use a different `uuidgen` output for each role group. This isolates API keys so compromising one key does not expose other node types.

Verify the files are encrypted:

```bash
# Should show $ANSIBLE_VAULT;1.1;AES256 header
head -1 inventory/group_vars/erigon/vault.yml

# View decrypted content (read-only)
ansible-vault view inventory/group_vars/erigon/vault.yml
ansible-vault view inventory/group_vars/ethereum/vault.yml
```

### Step 3: Create Latitude BM vault (AWS credentials for Certbot)

Skip this step for AWS-only deployments (EC2 uses IAM instance profiles).

Create an IAM user with Route 53 permissions (`route53:GetChange`, `route53:ListHostedZones`, `route53:ListHostedZonesByName`, `route53:ChangeResourceRecordSets`) and generate access keys in the AWS console.

```bash
# Create the encrypted vault file (opens your $EDITOR)
ansible-vault create inventory/group_vars/platform_latitude/vault.yml
```

Your editor opens. Add the AWS credentials, save, and close:

```yaml
---
vault_haproxy_certbot_aws_access_key: "<iam-access-key>"
vault_haproxy_certbot_aws_secret_key: "<iam-secret-key>"
```

### Step 4: Set deployment config (plaintext)

Edit `group_vars/all/main.yml` and set the certbot email:

```yaml
# group_vars/all/main.yml
haproxy_certbot_email: "admin@example.com"
```

> `haproxy_domain` is set per-node via Terraform (`domain` field in `nodes.tfvars`). Terraform creates Route 53 A records and passes `haproxy_domain` as a host variable automatically.

### Managing vault files

```bash
# Edit encrypted vault (opens editor, re-encrypts on save)
ansible-vault edit inventory/group_vars/erigon/vault.yml
ansible-vault edit inventory/group_vars/ethereum/vault.yml
ansible-vault edit inventory/group_vars/platform_latitude/vault.yml

# View encrypted vault (read-only, prints to terminal)
ansible-vault view inventory/group_vars/erigon/vault.yml
ansible-vault view inventory/group_vars/ethereum/vault.yml

# Re-key (change vault password across all vault files)
ansible-vault rekey inventory/group_vars/erigon/vault.yml
ansible-vault rekey inventory/group_vars/ethereum/vault.yml
ansible-vault rekey inventory/group_vars/platform_latitude/vault.yml
```

## Usage

Install dependencies:

```bash
cd ansible
ansible-galaxy collection install -r requirements.yml
```

### Prerequisites

All Ansible commands run from the `ansible/` directory:

```bash
cd ansible
export TF_TOKEN_app_terraform_io="your-api-token"
export ANSIBLE_PRIVATE_KEY_FILE=~/.ssh/your-key.pem
```

Host key checking is enabled. Ensure hosts are present in `~/.ssh/known_hosts` before deployment.

### Playbook Selection

Match the playbook to the `role` field in your `nodes.tfvars`:

| `role` in nodes.tfvars | Playbook | Clients | Deployment |
|------------------------|----------|---------|------------|
| `ethereum` | `playbooks/ethereum.yml` | Geth+Prysm, Reth+Lighthouse | Docker |
| `erigon` | `playbooks/erigon.yml` | Erigon+Caplin | Binary build |

If your inventory has nodes with different roles, run each playbook separately with `--limit`.

### Inventory File Selection

Pick the inventory file that matches your platform and network:

| Platform | Network | Inventory File |
|----------|---------|----------------|
| AWS | Mainnet | `inventory/ethereum_mainnet_aws_terraform_state.yml` |
| AWS | Sepolia | `inventory/ethereum_sepolia_aws_terraform_state.yml` |
| Latitude BM | Mainnet | `inventory/ethereum_mainnet_latitude_terraform_state.yml` |
| Latitude BM | Sepolia | `inventory/ethereum_sepolia_latitude_terraform_state.yml` |

### Deployment Scenarios

> **Before deploying:** If you need HAProxy (TLS + API key auth), complete the [Ansible Vault Setup](#ansible-vault-setup) first. Without vault files, HAProxy deploys without API key protection. You can add vault files later and re-run with `--tags haproxy`.

#### Single role - all nodes same type

When all nodes in the inventory use the same role:

```bash
# All Docker nodes (Geth+Prysm, Reth+Lighthouse) - AWS Mainnet
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/ethereum.yml

# All Erigon nodes (binary build) - AWS Mainnet
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/erigon.yml

# All Erigon nodes - AWS Sepolia
ansible-playbook -i inventory/ethereum_sepolia_aws_terraform_state.yml playbooks/erigon.yml

# All Docker nodes - AWS Sepolia
ansible-playbook -i inventory/ethereum_sepolia_aws_terraform_state.yml playbooks/ethereum.yml
```

#### Mixed roles - Ethereum + Erigon on the same platform

When your `nodes.tfvars` has nodes with different roles (e.g., a Geth+Prysm full node and an Erigon archive node), run each playbook separately with `--limit`:

```bash
INV=inventory/ethereum_mainnet_aws_terraform_state.yml

# Step 1: Deploy the Ethereum full node (Geth+Prysm, Docker)
ansible-playbook -i $INV playbooks/ethereum.yml --limit node_full

# Step 2: Deploy the Erigon archive node (binary build)
ansible-playbook -i $INV playbooks/erigon.yml --limit node_archive
```

Without `--limit`, the playbook runs against all nodes. Using `--limit` avoids unnecessary connection attempts to nodes that belong to a different role.

#### Specific node only

Deploy or reconfigure a single node:

```bash
# Docker full node only
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/ethereum.yml --limit node_full

# Docker archive node only
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/ethereum.yml --limit node_archive

# Erigon full node only (AWS)
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/erigon.yml --limit node_full

# Erigon archive node only (AWS)
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/erigon.yml --limit node_archive

# Erigon full node only (Latitude BM)
ansible-playbook -i inventory/ethereum_mainnet_latitude_terraform_state.yml playbooks/erigon.yml --limit node_full

# Multiple node groups
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/ethereum.yml --limit "node_full,node_archive"
```

#### Latitude BM (RAID-0 + node deployment)

Latitude bare metal servers may have multiple data disks. Run RAID setup first:

```bash
INV=inventory/ethereum_mainnet_latitude_terraform_state.yml

# Step 1: Verify connectivity
ansible -i $INV all -m ping

# Step 2: Setup RAID-0 (skip if BM has only 1 data disk)
ansible-playbook -i $INV playbooks/raid.yml

# Step 3: Deploy nodes (choose the correct playbook for your role)
ansible-playbook -i $INV playbooks/ethereum.yml   # Docker nodes
ansible-playbook -i $INV playbooks/erigon.yml      # Erigon nodes
```

For mixed roles on Latitude BM:

```bash
INV=inventory/ethereum_mainnet_latitude_terraform_state.yml

ansible-playbook -i $INV playbooks/raid.yml
ansible-playbook -i $INV playbooks/ethereum.yml --limit node_full
ansible-playbook -i $INV playbooks/erigon.yml --limit node_archive
```

RAID on a specific node only:

```bash
ansible-playbook -i inventory/ethereum_mainnet_latitude_terraform_state.yml playbooks/raid.yml --limit node_full
```

#### HAProxy only

Deploy or update HAProxy without touching the node:

```bash
# HAProxy only - Erigon nodes
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/erigon.yml --tags haproxy

# HAProxy only - Docker nodes
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/ethereum.yml --tags haproxy

# HAProxy only - Latitude BM
ansible-playbook -i inventory/ethereum_mainnet_latitude_terraform_state.yml playbooks/erigon.yml --tags haproxy

# Deploy node without HAProxy
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/erigon.yml --skip-tags haproxy
```

#### Static inventory (no Terraform)

For manually provisioned servers (see [Static Inventory Guide](static-inventory.md)):

```bash
ansible-playbook -i inventory/ethereum_sepolia_hosts.yml playbooks/erigon.yml
```

#### Dry-run

Preview changes without applying:

```bash
ansible-playbook -i inventory/ethereum_mainnet_aws_terraform_state.yml playbooks/erigon.yml --check --diff
```
